{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain-openai\n",
    "# !pip install langchain-huggingface \n",
    "# !pip install faiss-cpu\n",
    "\n",
    "\n",
    "# :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import json\n",
    "# from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.document_loaders import TextLoader, CSVLoader, JSONLoader, PyPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the csv file which has the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754079\n"
     ]
    }
   ],
   "source": [
    "filename = \"Resources\\AmazonHomeKitchenReviews.csv\"\n",
    "# Load dataset (modify path as needed)\n",
    "df = pd.read_csv(filename)\n",
    "df.head(1)\n",
    "print(len(df))\n",
    "df_renamed = df.rename(columns={'title_y' : 'product_title','title_x':'review_title','text':'review_text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load the api key for HuggingfaceRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with your own env file containing API keys\n",
    "load_dotenv(find_dotenv('Resources\\keys.env'))\n",
    "huggingfacehubapi = os.getenv('HuggingfaceRead')\n",
    "# print(huggingfacehubapi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to load csv as documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_docs(doc):\n",
    "    loader = CSVLoader(doc)\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 59\n",
      "rating: 5\n",
      "title_x: Adorable!\n",
      "text: These are so sweet. I do wish the stopper part was a little longer in length but they work great.\n",
      "images: []\n",
      "asin: B01HBWGU80\n",
      "parent_asin: B01DR2ACA0\n",
      "user_id: AGKHLEW2SOWHNMFQIJGBECAF7INQ\n",
      "timestamp: 2019-07-23 04:29:16.671\n",
      "helpful_vote: 0\n",
      "verified_purchase: True\n",
      "title_y: Little Bird Wine Bottle Stopper, Silicone Stoppers, Reusable, Leak Proof, Cute, Fun, Decorative, Multipack (Assorted Color, Set of 6)\n",
      "description: []\n",
      "price: 9.49\n",
      "Brand: LouisChoice\n",
      "Material: Silicone\n",
      "Color: Assorted Color\n",
      "categories: ['Home & Kitchen', 'Kitchen & Dining', 'Kitchen Utensils & Gadgets', 'Bar & Wine Tools', 'Wine Stoppers & Pourers', 'Wine Stoppers']\n"
     ]
    }
   ],
   "source": [
    "docs = load_docs(filename)  # Change the filename accordingly\n",
    "print(docs[0].page_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the HuggingFaceEmbeddingsModel which is free and has no limit on the number of embeddings\n",
    "## OpenAIembeddings has limit on the number of embeddings and would add a cost to the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the function to create the page_content out of the product title, price,rating,color,categories,reviewtitle and review text of which the embeddings will be generated and will be used for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(df, start_index=0):\n",
    "    \"\"\"Convert DataFrame into a list of Documents from a specific index onward.\"\"\"\n",
    "    docs = []\n",
    "    for idx, row in df.iloc[start_index:].iterrows():\n",
    "        # content = f\"Title: {row.get('review_title', '')}. Review: {row.get('review_text', '')}\"\n",
    "        content = f\"Product: {row.get('product_title', 'Unknown')}. Price: ${row.get('price', 'N/A')}.Rating: {row.get('rating', 'N/A')} stars. Color: {row.get('Color', 'N/A')}. Categories: {row.get('categories', 'N/A')}. ReviewTitle: {row.get('review_title', '')}. Review: {row.get('review_text', '')}\"   \n",
    "        doc = Document(page_content=content, metadata={\"rating\": row.get(\"rating\", \"N/A\"),\"price\": row.get(\"price\", \"N/A\"),\"product_title\": row.get(\"product_title\", \"N/A\"),\"parent_asin\": row.get(\"parent_asin\", \"N/A\") ,\"index\": idx })\n",
    "        docs.append(doc)\n",
    "        # print(idx)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the records in the dataframe as documents using the load_docs function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_size = 0    \n",
    "# Get new documents to embed\n",
    "docs = load_docs(df_renamed, start_index=existing_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the page_content for one of the docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754079\n",
      "page_content='Product: Fortune Candy 8-Inch Fry Pan with Lid, 3-ply Skillet, 18/8 Stainless Steel, Dishwasher Safe, Induction Ready, Silver (Mirror Finish). Price: $24.99.Rating: 5 stars. Color: Mirror Finish. Categories: ['Home & Kitchen', 'Kitchen & Dining', 'Cookware', 'Pots & Pans', 'Skillets']. ReviewTitle: Stailess, healthier than coated pans. Review: Great little stainless steel, balanced, good weight, frying pan with lide' metadata={'rating': 5, 'price': 24.99, 'product_title': 'Fortune Candy 8-Inch Fry Pan with Lid, 3-ply Skillet, 18/8 Stainless Steel, Dishwasher Safe, Induction Ready, Silver (Mirror Finish)', 'parent_asin': 'B08C7JYKZH', 'index': 1}\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print((docs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the path for the vector database.  If the path does not exists it will create the folder and create the vector for the first batch of 500 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS index...\n",
      "Existing FAISS index has 205500 embeddings.\n"
     ]
    }
   ],
   "source": [
    "faiss_index_path = \"Resources/vector\"  \n",
    "\n",
    "batch_size = 500 \n",
    "# Check if FAISS index exists\n",
    "if os.path.exists(faiss_index_path):\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    vector_store = FAISS.load_local(faiss_index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "    existing_size = vector_store.index.ntotal  # Number of vectors stored\n",
    "    print(f\"Existing FAISS index has {existing_size} embeddings.\")\n",
    "else:\n",
    "    print(\"Creating new FAISS index...\")\n",
    "    os.makedirs(os.path.dirname(faiss_index_path))\n",
    "    # vector_store = None\n",
    "    # vector_store = FAISS.from_documents(docs[:batch_size], embedding_model)\n",
    "    # vector_store.save_local(faiss_index_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function will create the vector embeddings in batches and will store the vector file locally for every batch.  This way if we terminate this function, it will pick up from where it left off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_incrementally_in_faiss(docs, faiss_index_path, batch_size=500):\n",
    "    \"\"\"Loads existing FAISS index, adds new embeddings in batches, and saves back.\"\"\"\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(os.path.dirname(faiss_index_path)):\n",
    "        os.makedirs(os.path.dirname(faiss_index_path))\n",
    "\n",
    "    # Check if FAISS index exists\n",
    "    if os.path.exists(faiss_index_path):\n",
    "        print(\"Loading existing FAISS index...\")\n",
    "        vector_store = FAISS.load_local(faiss_index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "        existing_size = vector_store.index.ntotal  # Number of vectors stored\n",
    "        print(f\"Existing FAISS index contains {existing_size} embeddings.\")\n",
    "        start_index = existing_size//batch_size\n",
    "    else:\n",
    "        print(\"Creating new FAISS index...\")\n",
    "        vector_store = None\n",
    "        existing_size = 0\n",
    "\n",
    "    # Get only new documents\n",
    "    new_docs = docs[existing_size:]\n",
    "    \n",
    "    if not new_docs:\n",
    "        print(\"No new documents to embed. FAISS index is up-to-date.\")\n",
    "        return\n",
    "\n",
    "    # Process remaining documents in batches and save each batch as they are generated\n",
    "    # Even if this fails , it can start from where it left off \n",
    "    for i in range(start_index, len(new_docs), batch_size):\n",
    "        batch = new_docs[i:i + batch_size]\n",
    "        print(f\"Processing batch {i // batch_size + 1} with {len(batch)} documents starting from index {start_index}...\")\n",
    "        vector_store.add_documents(batch)  # Always add to the existing vector store\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "        existing_size = vector_store.index.ntotal  # Number of vectors stored\n",
    "        start_index = existing_size//batch_size\n",
    "\n",
    "        \n",
    "    # Check if FAISS index was created\n",
    "    if os.path.exists(faiss_index_path + \".index\"):\n",
    "        print(f\"FAISS index successfully saved at: {faiss_index_path}\")\n",
    "    else:\n",
    "        print(\"FAISS index was NOT created! Check for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the store_incrementally_in_fiass function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_incrementally_in_faiss(docs,faiss_index_path,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
