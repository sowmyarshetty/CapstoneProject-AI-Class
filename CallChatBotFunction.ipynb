{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a204f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import json\n",
    "# from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.document_loaders import TextLoader, CSVLoader, JSONLoader, PyPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f097b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with your own env file containing API keys\n",
    "load_dotenv(find_dotenv('Resources\\keys.env'))\n",
    "huggingfacehubapi = os.getenv('HuggingfaceRead')\n",
    "# print(huggingfacehubapi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a550a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dcc7eb",
   "metadata": {},
   "source": [
    "## Create the function to load the vector database and chat.  Using HuggingFaceEndpoint mistralai/Mistral-7B-Instruct-v0.1 as the LLM . \n",
    "## Create a question answer retreival chain from langchain.chains framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81332367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "faiss_index_path = \"Resources/vector\"  \n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "def load_faiss_and_chat(faiss_index_path=faiss_index_path):\n",
    "    \"\"\"Loads FAISS and creates a chatbot using Hugging Face LLM.\"\"\"\n",
    "    \n",
    "    # Load FAISS vector store\n",
    "    vector_store = FAISS.load_local(faiss_index_path, embedding_model,allow_dangerous_deserialization=True)\n",
    "\n",
    "    \n",
    "    llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=512,\n",
    "    huggingfacehub_api_token=huggingfacehubapi)\n",
    "\n",
    "\n",
    "    # # Custom prompt template\n",
    "    # prompt_template = PromptTemplate(\n",
    "    #     input_variables=[\"context\", \"question\"],\n",
    "    #     template=\"\"\"You are an intelligent assistant answering questions based on the context below. \n",
    "    #     If the answer is not in the context, say you don't know. \n",
    "    #     Use a tone like you're chatting with someone in a store. \n",
    "    #     Context:{context}\n",
    "    #     Question: {question}\n",
    "    #     Answer:\"\"\")\n",
    "\n",
    "    # Custom prompt template\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\",\"chat_history\"],\n",
    "        template=\"\"\"You are a helpful store assistant helping a customer based on the reviews and product info below. \n",
    "        If the answer is not in the context, say \"I don't know.\" \n",
    "        When making recommendations, provide only the top 3 distinct products in the following format: \n",
    "        Make sure to return the top 3 distinct recommendations. If there are duplicates, choose only one entry for each product.\n",
    "        **Recommendations**\n",
    "        1. [Product Title] , [price] , [color]\n",
    "            **Review**:[short summary from reviews]\n",
    "        Do not display the raw product data or context. Focus on generating helpful recommendations in a conversational tone.\n",
    "        Chat History:\n",
    "        {chat_history}\n",
    "\n",
    "        Question: {question}\n",
    "        Context:{context}\n",
    "        Answer:\"\"\")\n",
    "\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                                     retriever=vector_store.as_retriever(),\n",
    "                                                     memory=memory,\n",
    "                                                     combine_docs_chain_kwargs={\"prompt\" : prompt_template})\n",
    "\n",
    "\n",
    "    # # Create a QA chain using retrieval\n",
    "    # qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vector_store.as_retriever(),\n",
    "    #                                         chain_type_kwargs={\"prompt\": prompt_template},\n",
    "    #                                         return_source_documents=False)\n",
    "\n",
    "    while True:\n",
    "        memory.clear()\n",
    "        query = input(\"\\nAsk a question (or type 'exit' to quit),'reset' to clear memory: \")\n",
    "        if query.lower() == \"exit\":         \n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        elif query.lower() == \"reset\":\n",
    "            memory.clear()\n",
    "            print(\"Memory has been cleared\")\n",
    "            continue\n",
    "        response = qa_chain.invoke(query)\n",
    "        print(f\"\\n Chatbot: {response['answer']}\") \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7fb4153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot:  Hello! How may I assist you today?\n",
      "\n",
      " Chatbot: \n",
      "        1. BJPKPK 2 pcs Insulated Coffee Mug, 14oz Insulated Coffee Mug with Lid, Stainless Steel Insulated Coffee Mug with Splash Proof Lid-White. Price: $16.99.Rating: 5 stars. Color: White-14oz.\n",
      "            **Review**: The mugs are great at keeping my coffee piping hot and the color is bright.\n",
      "        2. Coffee Travel Mug, 14OZ Double Walled Insulated Vacuum Coffee Tumbler With Leakproof Flip Insulated Coffee Mug, For Hot And Cold Water Coffee And Tea In Travel Car Office School Camping (Light Green). Price: $14.99.Rating: 4 stars. Color: Light Green.\n",
      "            **Review**: The mug keeps coffee warm nearly all day and fits cupholders.\n",
      "        3. U.S. Navy Customizable Rank Insignia Ceramic Coffee/Cocoa Mug by Carpe Diem Designs, Made in the U.S.A.. Price: $17.95.Rating: 5 stars. Color: E4.\n",
      "            **Review**: The cup is well made and looks good, and it has a good size and value.\n",
      "\n",
      " Chatbot: \n",
      "        I'm sorry to hear that the cup you were looking for doesn't fit in your car's cup holder. Based on the reviews and product information provided, here are my top 3 recommendations:\n",
      "\n",
      "        1. RTIC Double Wall Vacuum Insulated Tumbler, 30 oz, Orange. This tumbler is highly rated and fits in a variety of cup holders, including those in a Nissan Rogue. It's also a great price and has excellent performance.\n",
      "        2. Beast 40 oz Tumbler Stainless Steel Vacuum Insulated Coffee Ice Cup Double Wall Travel Flask (Purple). While this tumbler is not a great fit for cup holders, it's highly rated and has great quality. It's also a good price.\n",
      "        3. RTIC 40 oz Insulated Tumbler Stainless Steel Coffee Travel Mug with Lid, Spill Proof, Hot Beverage and Cold, Portable Thermal Cup for Car, Camping. This tumbler is also highly rated and has excellent performance. While it doesn't fit in all cup holders, it's still a great option for those looking for an insulated tumbler.\n",
      "\n",
      " Chatbot:  Based on the reviews you've provided, I would recommend the Beast 40 oz Tumbler Stainless Steel Vacuum Insulated Coffee Ice Cup Double Wall Travel Flask (Purple) as a reliable and effective solution for keeping your drinks cold for an extended period of time. It's durable, easy to use, and clean. The color finish seems to be indestructible and the plastic lid with a good gasket keeps spills from making a mess. \n",
      "\n",
      "        I don't know of any other products that could be more effective or better quality than this Beast. It's my second Beast tumbler and I highly recommend it.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "load_faiss_and_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
