{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-openai) (0.3.50)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-openai) (1.70.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-huggingface) (0.29.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-huggingface) (0.3.50)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-huggingface) (3.4.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-huggingface) (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: networkx in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages (from faiss-cpu) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai\n",
    "!pip install langchain-huggingface \n",
    "!pip install faiss-cpu\n",
    "\n",
    "\n",
    "# :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import json\n",
    "# from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.document_loaders import TextLoader, CSVLoader, JSONLoader, PyPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the csv file which has the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754079\n"
     ]
    }
   ],
   "source": [
    "filename = \"Resources\\AmazonHomeKitchenReviews.csv\"\n",
    "# Load dataset (modify path as needed)\n",
    "df = pd.read_csv(filename)\n",
    "df.head(1)\n",
    "print(len(df))\n",
    "df_renamed = df.rename(columns={'title_y' : 'product_title','title_x':'review_title','text':'review_text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load the api key for HuggingfaceRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with your own env file containing API keys\n",
    "load_dotenv(find_dotenv('Resources\\keys.env'))\n",
    "huggingfacehubapi = os.getenv('HuggingfaceRead')\n",
    "# print(huggingfacehubapi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to load csv as documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_docs(doc):\n",
    "    loader = CSVLoader(doc)\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 59\n",
      "rating: 5\n",
      "title_x: Adorable!\n",
      "text: These are so sweet. I do wish the stopper part was a little longer in length but they work great.\n",
      "images: []\n",
      "asin: B01HBWGU80\n",
      "parent_asin: B01DR2ACA0\n",
      "user_id: AGKHLEW2SOWHNMFQIJGBECAF7INQ\n",
      "timestamp: 2019-07-23 04:29:16.671\n",
      "helpful_vote: 0\n",
      "verified_purchase: True\n",
      "title_y: Little Bird Wine Bottle Stopper, Silicone Stoppers, Reusable, Leak Proof, Cute, Fun, Decorative, Multipack (Assorted Color, Set of 6)\n",
      "description: []\n",
      "price: 9.49\n",
      "Brand: LouisChoice\n",
      "Material: Silicone\n",
      "Color: Assorted Color\n",
      "categories: ['Home & Kitchen', 'Kitchen & Dining', 'Kitchen Utensils & Gadgets', 'Bar & Wine Tools', 'Wine Stoppers & Pourers', 'Wine Stoppers']\n"
     ]
    }
   ],
   "source": [
    "docs = load_docs(filename)  # Change the filename accordingly\n",
    "print(docs[0].page_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the HuggingFaceEmbeddingsModel which is free and has no limit on the number of embeddings\n",
    "## OpenAIembeddings has limit on the number of embeddings and would add a cost to the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the function to create the page_content out of the product title, price,rating,color,categories,reviewtitle and review text of which the embeddings will be generated and will be used for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(df, start_index=0):\n",
    "    \"\"\"Convert DataFrame into a list of Documents from a specific index onward.\"\"\"\n",
    "    docs = []\n",
    "    for idx, row in df.iloc[start_index:].iterrows():\n",
    "        # content = f\"Title: {row.get('review_title', '')}. Review: {row.get('review_text', '')}\"\n",
    "        content = f\"Product: {row.get('product_title', 'Unknown')}. Price: ${row.get('price', 'N/A')}.Rating: {row.get('rating', 'N/A')} stars. Color: {row.get('Color', 'N/A')}. Categories: {row.get('categories', 'N/A')}. ReviewTitle: {row.get('review_title', '')}. Review: {row.get('review_text', '')}\"   \n",
    "        doc = Document(page_content=content, metadata={\"rating\": row.get(\"rating\", \"N/A\"),\"price\": row.get(\"price\", \"N/A\"),\"product_title\": row.get(\"product_title\", \"N/A\"),\"parent_asin\": row.get(\"parent_asin\", \"N/A\") ,\"index\": idx })\n",
    "        docs.append(doc)\n",
    "        # print(idx)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the records in the dataframe as documents using the load_docs function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_size = 0    \n",
    "# Get new documents to embed\n",
    "docs = load_docs(df_renamed, start_index=existing_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the page_content for one of the docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754079\n",
      "page_content='Product: Fortune Candy 8-Inch Fry Pan with Lid, 3-ply Skillet, 18/8 Stainless Steel, Dishwasher Safe, Induction Ready, Silver (Mirror Finish). Price: $24.99.Rating: 5 stars. Color: Mirror Finish. Categories: ['Home & Kitchen', 'Kitchen & Dining', 'Cookware', 'Pots & Pans', 'Skillets']. ReviewTitle: Stailess, healthier than coated pans. Review: Great little stainless steel, balanced, good weight, frying pan with lide' metadata={'rating': 5, 'price': 24.99, 'product_title': 'Fortune Candy 8-Inch Fry Pan with Lid, 3-ply Skillet, 18/8 Stainless Steel, Dishwasher Safe, Induction Ready, Silver (Mirror Finish)', 'parent_asin': 'B08C7JYKZH', 'index': 1}\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print((docs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the path for the vector database.  If the path does not exists it will create the folder and create the vector for the first batch of 500 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new FAISS index...\n"
     ]
    }
   ],
   "source": [
    "faiss_index_path = \"Resources/vector\"  \n",
    "\n",
    "batch_size = 500 \n",
    "# Check if FAISS index exists\n",
    "if os.path.exists(faiss_index_path):\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    vector_store = FAISS.load_local(faiss_index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "    existing_size = vector_store.index.ntotal  # Number of vectors stored\n",
    "    print(f\"Existing FAISS index has {existing_size} embeddings.\")\n",
    "else:\n",
    "    print(\"Creating new FAISS index...\")\n",
    "    # vector_store = None\n",
    "    vector_store = FAISS.from_documents(docs[:batch_size], embedding_model)\n",
    "    vector_store.save_local(faiss_index_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function will create the vector embeddings in batches and will store the vector file locally for every batch.  This way if we terminate this function, it will pick up from where it left off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_incrementally_in_faiss(docs, faiss_index_path, batch_size=500):\n",
    "    \"\"\"Loads existing FAISS index, adds new embeddings in batches, and saves back.\"\"\"\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(os.path.dirname(faiss_index_path)):\n",
    "        os.makedirs(os.path.dirname(faiss_index_path))\n",
    "\n",
    "    # Check if FAISS index exists\n",
    "    if os.path.exists(faiss_index_path):\n",
    "        print(\"Loading existing FAISS index...\")\n",
    "        vector_store = FAISS.load_local(faiss_index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "        existing_size = vector_store.index.ntotal  # Number of vectors stored\n",
    "        print(f\"Existing FAISS index contains {existing_size} embeddings.\")\n",
    "        start_index = existing_size//batch_size\n",
    "    else:\n",
    "        print(\"Creating new FAISS index...\")\n",
    "        vector_store = None\n",
    "        existing_size = 0\n",
    "\n",
    "    # Get only new documents\n",
    "    new_docs = docs[existing_size:]\n",
    "    \n",
    "    if not new_docs:\n",
    "        print(\"No new documents to embed. FAISS index is up-to-date.\")\n",
    "        return\n",
    "\n",
    "    # Process remaining documents in batches and save each batch as they are generated\n",
    "    # Even if this fails , it can start from where it left off \n",
    "    for i in range(start_index, len(new_docs), batch_size):\n",
    "        batch = new_docs[i:i + batch_size]\n",
    "        print(f\"Processing batch {i // batch_size + 1} with {len(batch)} documents starting from index {start_index}...\")\n",
    "        vector_store.add_documents(batch)  # Always add to the existing vector store\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "        existing_size = vector_store.index.ntotal  # Number of vectors stored\n",
    "        start_index = existing_size//batch_size\n",
    "\n",
    "        \n",
    "    # Check if FAISS index was created\n",
    "    if os.path.exists(faiss_index_path + \".index\"):\n",
    "        print(f\"FAISS index successfully saved at: {faiss_index_path}\")\n",
    "    else:\n",
    "        print(\"FAISS index was NOT created! Check for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the store_incrementally_in_fiass function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_incrementally_in_faiss(docs,faiss_index_path,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the function to load the vector database and chat.  Using HuggingFaceEndpoint mistralai/Mistral-7B-Instruct-v0.1 as the LLM . \n",
    "## Create a question answer retreival chain from langchain.chains framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sowmy\\AppData\\Local\\Temp\\ipykernel_15380\\738498459.py:25: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(query)\n",
      "c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot:  I'm sorry, but I don't see any information provided about sunglasses in the context you provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot:  None of the products provided are table lamps, they are either fairy lights, lanterns, or tablecloths.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot:  The kitchenAid Cordless Variable Speed Hand Blender with Chopper and Whisk Attachment - KHBBV83 and the BlenderBottle Classic V2 Shaker Bottle Perfect for Protein Shakes and Pre Workout, 28-Ounce, Clear/Black are highly rated blenders with a rating of 5 stars.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot:  Based on the given context, the top 5 highly rated blenders are:\n",
      "\n",
      "1. KitchenAid Cordless Variable Speed Hand Blender with Chopper and Whisk Attachment - KHBBV83\n",
      "2. Zulay Powerful Milk Frother for Coffee with Upgraded Titanium Motor - Handheld Frother Whisk, Milk Froamer, Mini Blender and Electric Mixer Coffee Frother for Frappe, Latte, Matcha, No Stand - Galaxy\n",
      "3. KitchenIQ 50881 - Edge Grip 2-Stage Knife Sharpener - Green - Coarse & Fine Sharpeners - Compact for Easy Storage - Stable Non-Slip Base - Soft Grip Rubber Handle - Straight & Serrated Knives\n",
      "4. Vinturi Red Wine Aerator Includes Base Enhanced Flavors with Smoother Finish, Black\n",
      "5. Product: Hamilton Beach 15150 - Keep-Cups - 5-Cup Coffee Maker with Single Serve - Black/Silver. Price: $39.95.Rating: 5 stars. Color: Black/Silver. Categories: ['Home & Kitchen', 'Kitchen & Dining', 'Coffee, Tea & Espresso', 'Single Serve Coffee Makers']. ReviewTitle: Great!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot:  I don't know about vitamix branded products, but here are five highly rated products in the categories you provided:\n",
      "\n",
      "1. DII Basic Ribbed Terry Kitchen Basics Collection, Blue, Kitchen Set, 8 Piece. Rating: 5 stars.\n",
      "2. Cotton Paradise 6 Piece Towel Set, 100% Turkish Cotton Soft Absorbent Towels for Bathroom, 2 Bath Towels 2 Hand Towels 2 Washcloths, Sky Blue Towel Set. Rating: 4 stars.\n",
      "3. HomeLights Luxury Scented Candle, Natural Soy Wax, Home Fragrance Decor Gift, Iris & Orange Blossom, Medium Jar. Rating: 5 stars.\n",
      "4. Beauty Threadz - 2 Bath Towels, 2 Hand Towels, & 4 Washcloths 100% Ringspun Cotton Hotel & Spa Quality 8 Piece Towel Set Ultra Soft & Fade Resistant Pack of 8 Cotton Towel Set 400 GSM (Black). Rating: 3 stars.\n",
      "5. Beauty Threadz - 2 Bath Towels, 2 Hand Towels, & 4 Washcloths 100% Ringspun Cotton Hotel & Spa Quality 8 Piece Towel Set Ultra Soft & Fade Resistant Pack of 8 Cotton Towel Set 400 GSM (Black). Rating: 3 stars.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sowmy\\.conda\\envs\\dev\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot:  I'm sorry but I don't know the answer to this question as I don't have the necessary information about the top 5 highly rated vitamix blenders.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def load_faiss_and_chat(faiss_index_path=faiss_index_path):\n",
    "    \"\"\"Loads FAISS and creates a chatbot using Hugging Face LLM.\"\"\"\n",
    "    \n",
    "    # Load FAISS vector store\n",
    "    vector_store = FAISS.load_local(faiss_index_path, embedding_model,allow_dangerous_deserialization=True)\n",
    "\n",
    "    \n",
    "    llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=512,\n",
    "    huggingfacehub_api_token=huggingfacehubapi)\n",
    "\n",
    "    # Create a QA chain using retrieval\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vector_store.as_retriever())\n",
    "\n",
    "    while True:\n",
    "        query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        response = qa_chain.run(query)\n",
    "        print(f\"\\n Chatbot: {response}\")\n",
    "\n",
    "# Run the chatbot\n",
    "load_faiss_and_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
